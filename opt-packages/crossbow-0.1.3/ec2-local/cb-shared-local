#!/bin/bash

##
# cb-shared-local
#
# Authors: Ben Langmead & Michael C. Schatz
#    Date: Sept 1, 2009
#

#
# Check that all needed environment variables are set.
#
check_env() {
	[ -z "$AWS_ACCOUNT_ID" ]        && echo "Error, AWS_ACCOUNT_ID environment variable must be set" && usagedie
	[ -z "$AWS_ACCESS_KEY_ID" ]     && echo "Error, AWS_ACCESS_KEY_ID environment variable must be set" && usagedie
	[ -z "$AWS_SECRET_ACCESS_KEY" ] && echo "Error, AWS_SECRET_ACCESS_KEY environment variable must be set" && usagedie
	[ -z "$EC2_PRIVATE_KEY" ]       && echo "Error, EC2_PRIVATE_KEY environment variable must be set" && usagedie
	if [ ! -f "$EC2_PRIVATE_KEY" ] ; then
		echo "Error, file specified in EC2_PRIVATE_KEY environment variable doesn't exist"
		usagedie
	fi
	echo "Using AWS account id: $AWS_ACCOUNT_ID"
	echo "Using EC2 private key file: $EC2_PRIVATE_KEY"
}

#
# Install critical information stored in environment variables into the
# relevant scripts.
# 
install_env() {
	[ -z $MAP_MAX ] && echo "Must set MAP_MAX before calling install_env" && exit 1
	[ -z $REDUCE_MAX ] && echo "Must set REDUCE_MAX before calling install_end" && exit 1
	[ -z $FAIL_MAX ] && echo "Must set FAIL_MAX before calling install_end" && exit 1

	EC2_KEYDIR=`dirname "$EC2_PRIVATE_KEY"`
	KEY_NAME=gsg-keypair
	PRIVATE_KEY_PATH=`echo "$EC2_KEYDIR"/"id_rsa-$KEY_NAME"`

	# Useful vars
	ssh_opts="-o StrictHostKeyChecking=no -o ServerAliveInterval=30"
	ec2_scp="scp -i $PRIVATE_KEY_PATH $ssh_opts"
	ec2_ssh="ssh -i $PRIVATE_KEY_PATH $ssh_opts"

	sed -e "s|%MAP_MAX%|$MAP_MAX|" $d/bin/hadoop-ec2-init-remote.sh.in \
		| sed -e "s|%REDUCE_MAX%|$REDUCE_MAX|" \
		| sed -e "s|%FAIL_MAX%|$FAIL_MAX|" \
		| sed -e "s|%wofileS%|$wofileS|" \
		> $d/bin/hadoop-ec2-init-remote.sh
	sed -e "s|%AWS_ACCESS_KEY_ID%|$AWS_ACCESS_KEY_ID|" $d/../ec2-master/s3cfg.in \
		| sed -e "s|%AWS_SECRET_ACCESS_KEY%|$AWS_SECRET_ACCESS_KEY|" \
		> .s3cfg
	
	# Check
	if [ ! -f $d/bin/hadoop-ec2 ] ; then
		echo "Could not find $d/bin/hadoop-ec2"
		exit 1
	fi
	
	# Note that EC2 scripts use "hadooop" (w/ 3 o's) for some reason
	mafile=$HOME/.hadooop-${cluster_name}-master
	wofile=$HOME/.hadooop-${cluster_name}-workers
}

#
# Copy key environment variables into .bash_profile on master node
#
push_env() {
	echo -n "  pushing environment variables to master at: " ; date
	[ -z "$ec2_ssh_master" ] && echo "ec2_ssh_master must be set for push_env" && exit 1
	$ec2_ssh_master "echo 'export AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID' >> .bash_profile"
	$ec2_ssh_master "echo 'export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID' >> .bash_profile"
	$ec2_ssh_master "echo 'export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY' >> .bash_profile"
}

##
# Check for telltale error files on each worker and print them out if
# they exist
#
check_workers_for_errors() {
	[ -z "${wofile}" ] && die "wofile must be set in check_workers_for_errors" && exit 1
	for wrkr in `cat ${wofile} 2>/dev/null` ; do
		# check for existence of error files
		if $ec2_ssh root@$wrkr ls .*.*err 2> /dev/null ; then
			echo "Error(s) on worker $wrkr:"
			echo "== Begin errors =="
			# cat all the error files
			$ec2_ssh root@$wrkr cat .*.*err 2> /dev/null
			echo "== End error =="
			echo "If you see several MD5 errors, it's very likely that the MD5 specified for the"
			echo "reference jar is incorrect.  If this is the case, please abort (ctrl-c),"
			echo "terminate the cluster with 'cb-terminate ${cluster_name}' and try"
			echo "again with the correct reference jar MD5."
		fi
	done
}

##
# Spin in a sleep loop until al
#
wait_for_workers_to_join() {
	[ -z "$ec2_ssh_master" ] && echo "ec2_ssh_master must be set before calling wait_for_workers_to_join" && exit 1
	targ_nodes=$1
	[ $targ_nodes -lt 1 ] && echo "targ_nodes must be set >0 in wait_for_workers_to_join" && exit 1
	join_type=$2
	[ -z "$join_type" ] && echo "join_type must be setnefore calling wait_for_workers_to_join" && exit 1
	echo -n "  waiting for all workers to register with $join_type at: " ; date
	c=0
	while true ; do
		# Wait until workers have joined; Amazon Hadoop images use
		# /mnt/hadoop/logs for logs, but Cloudera Hadoop images use
		# /var/log/hadoop
		nworkers=`${ec2_ssh_master} \
			cat /mnt/hadoop/logs/*${join_type}*.log /var/log/hadoop/*${join_type}*.log 2>/dev/null | \
			grep 'NetworkTopology: Adding a new node' | \
			grep -v localhost | \
			sort -u | \
			wc -l`
		if [ $nworkers -ge $targ_nodes ] ; then
			if [ $nworkers -ne $targ_nodes ] ; then
				# Emit warning
				echo "Warning, actual number of workers joining ${join_type}, $nworkers, exceeds target, $targ_nodes"
			fi
			break
		fi
		sleep 3
		# Every 5 iterations of the sleep loop, log into all the
		# workers and look for error files.  A common error that can be
		# caught this way is if the reference jar MD5 specified by the
		# user is incorrect.
		c=`expr $c + 1`
		if [ $c -gt 4 ] ; then
			# Try to grab the worker names
			ec2-describe-instances  | \
				grep 'INSTANCE'     | \
				grep -v "${MASTER}" | \
				awk '{print $4}'    | \
				grep '^ec2-' > ${wofile}
			c=0
			check_workers_for_errors
		fi
	done
}

check_jobtracker() {
	echo -n "  checking for JobTracker on master: " ; date
	if [ -z "$ec2_ssh_master" ] ; then
		echo "ec2_ssh_master must be set before calling check_jobtracker"
		exit 1
	fi
	jtracker=`${ec2_ssh_master} "ps aux | grep java | grep -c 'org\.apache\.hadoop\.mapred\.JobTracker\$'"`
	if [ $jtracker -eq 0 ] ; then
		# Try to start it
		echo -n "  couldn't find it; attempting to start manually: " ; date
		${ec2_ssh_master} 'source .bash_profile && $HADOOP_HOME/bin/hadoop-daemon.sh start jobtracker'
		sleep 2
		echo -n "  checking for JobTracker on master, 2nd time: " ; date
		jtracker=`${ec2_ssh_master} "ps aux | grep java | grep -c 'org\.apache\.hadoop\.mapred\.JobTracker\$'"`
		if [ $jtracker -eq 0 ] ; then
			echo "   still no job tracker running on master"
			exit 1
		fi
	fi
	echo
	echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
	echo
	echo "       HADOOP JOB TRACKER NOW AVAILABLE FOR MONITORING"
	echo
	echo " The JobTracker is now running on the master node.  To monitor"
	echo " your job via the JobTracker's web interface, point your web"
	echo " browser to:"
	echo
	echo "  http://${MASTER}:50030"
	echo
	echo " For complete access to all areas of the web interface"
	echo " (including e.g. task logs on the workers), you must"
	echo " establish an SSH tunnel from your computer to the cluster's"
	echo " master node and use your browser's proxy features.  The"
	echo " tunnel can be established with this command:"
	echo
	echo "  cb-proxy ${cluster_name}"
	echo
	echo " Leave this command running for as long as the access is"
	echo " needed.  Make sure that your browser is set to send DNS"
	echo " requests through the tunnel.  For information on how to"
	echo " configure your browser to use the proxy, see your browser's"
	echo " help files or the Hadoop documentation."
	echo
	echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
	echo
}

get_worker_names() {
	echo -n "  getting names of workers at: " ; date
	[ -z "$MASTER" ] && echo "MASTER must be set before calling get_worker_names" && exit 1
	[ -z "$wofile" ] && echo "wofile must be set before calling get_worker_names" && exit 1
	[ -z "$n" ] && echo "n must be set before calling get_worker_names" && exit 1
	while true ; do
		ec2-describe-instances  | \
			grep 'INSTANCE'     | \
			grep -v "${MASTER}" | \
			awk '{print $4}'    | \
			grep '^ec2-' > ${wofile}
		actual_workers=`cat ${wofile} | wc -l`
		if [ $n -le $actual_workers ] ; then
			if [ $n -ne $actual_workers ] ; then
				echo "Warning, actual number of workers $actual_workers exceeds requested number $n"
			fi
			break
		fi
		sleep 2
	done
	echo "  got:" ; cat ${wofile}
}

launch_cluster() {
	[ -z "$INSTANCE_TYPE" ] && echo "INSTANCE_TYPE must be set before calling launch_cluster" && exit 1
	[ -z "$n" ] && echo "n must be set before calling launch_cluster" && exit 1
	[ -z "$mafile" ] && echo "mafile must be set before calling launch_cluster" && exit 1
	[ -z "$wofile" ] && echo "wofile must be set before calling launch_cluster" && exit 1
	echo
	echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
	echo
	echo "   REMEMBER TO TERMINATE THE CLUSTER WHEN YOU'RE FINISHED"
	echo
	echo " You will be charged by Amazon for the time you use, even when"
	echo " the cluster is idle.  This script prompts you to terminate"
	echo " the cluster when the job has completed, but you may also use"
	echo " the following command at any time:"
	echo
	echo "   cb-terminate ${cluster_name}"
	echo
	echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
	echo
	rm -f $mafile $wofile
	echo -n "Starting ${n}-worker $INSTANCE_TYPE cluster at: " ; date
	chmod a+x $d/bin/hadoop-ec2
	$d/bin/hadoop-ec2 launch-cluster ${cluster_name} $n 2>&1 | tee .launch-cluster.stdout
	if grep -q 'InsufficientInstanceCapacity' .launch-cluster.stdout ; then
		echo "Could not recruit enough workers for the cluster; aborting..."
		exit 1
	fi
}
